{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b5ad8d",
   "metadata": {},
   "source": [
    "1. Introduction et Objectifs\n",
    "Apr√®s avoir explor√© le Content-Based Filtering (KNN) et le Machine Learning Supervis√© (Random Forest), nous abordons ici la troisi√®me famille de recommandation : le Collaborative Filtering.\n",
    "\n",
    "L'objectif de ce notebook : Impl√©menter l'algorithme SVD (Singular Value Decomposition).\n",
    "\n",
    "Contrairement aux mod√®les pr√©c√©dents, le SVD ne regarde pas le synopsis ou les genres.\n",
    "\n",
    "Il se base uniquement sur la matrice d'interactions : \"Qui a aim√© quoi\".\n",
    "\n",
    "Il permet de d√©couvrir des relations cach√©es (Latent Factors) entre les utilisateurs et les animes.\n",
    "\n",
    "Note : Ce notebook utilise la biblioth√®que scikit-surprise. Assure-toi de l'avoir install√©e : pip install scikit-surprise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62bc88",
   "metadata": {},
   "source": [
    "2. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e054fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cellule d'imports modifi√©e ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml  \n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# --- Nouvelle cellule : Chargement de la Configuration ---\n",
    "with open(\"../config/config_svd.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "DATA_PATH = config['data']['interactions_path']\n",
    "MIN_USER = config['preprocessing']['min_user_favorites']\n",
    "MIN_ANIME = config['preprocessing']['min_anime_favorites']\n",
    "N_COMPONENTS = config['model']['params']['n_components']\n",
    "\n",
    "# --- Cellule de chargement (Utilisation du YAML) ---\n",
    "df_favs = pd.read_csv(DATA_PATH)\n",
    "# ... \n",
    "# Utilisation des filtres :\n",
    "user_counts = df_favs['username'].value_counts()\n",
    "df_filtered = df_favs[df_favs['username'].isin(user_counts[user_counts >= MIN_USER].index)].copy()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cc14b",
   "metadata": {},
   "source": [
    "3. Chargement des Interactions (User Ratings)\n",
    "Le SVD a besoin d'un fichier o√π l'on voit quel utilisateur (user_id) a donn√© quelle note (rating) √† quel anime (anime_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1729bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Colonnes d√©tect√©es dans le fichier : ['username', 'fav_type', 'id']\n",
      "‚úÖ Fichier charg√© : (4178747, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>fav_type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ishikawas</td>\n",
       "      <td>anime</td>\n",
       "      <td>45649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ishikawas</td>\n",
       "      <td>anime</td>\n",
       "      <td>38680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ishikawas</td>\n",
       "      <td>anime</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ishikawas</td>\n",
       "      <td>anime</td>\n",
       "      <td>37510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ishikawas</td>\n",
       "      <td>anime</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username fav_type     id\n",
       "0  ishikawas    anime  45649\n",
       "1  ishikawas    anime  38680\n",
       "2  ishikawas    anime    795\n",
       "3  ishikawas    anime  37510\n",
       "4  ishikawas    anime    820"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CELLULE 3 : Chargement depuis RAW ---\n",
    "DATA_PATH = \"../data/raw/favs.csv\"\n",
    "\n",
    "# On charge le d√©but du fichier pour v√©rifier le format sans tout bloquer\n",
    "df_check = pd.read_csv(DATA_PATH, nrows=5)\n",
    "print(\"üîç Colonnes d√©tect√©es dans le fichier :\", df_check.columns.tolist())\n",
    "\n",
    "# Chargement complet (on force les types pour gagner de la RAM)\n",
    "# Si ton fichier est ENORME, ajoute nrows=1000000 pour tester\n",
    "df_favs = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# On nettoie les noms de colonnes (enl√®ve les espaces et met en minuscule)\n",
    "df_favs.columns = [c.strip().lower() for c in df_favs.columns]\n",
    "\n",
    "print(f\"‚úÖ Fichier charg√© : {df_favs.shape}\")\n",
    "df_favs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81cdd30",
   "metadata": {},
   "source": [
    "4. Analyse de la Matrice (Sparsity)\n",
    "√âtape indispensable en Master pour justifier l'usage du SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16237a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Colonnes pr√©sentes dans le fichier : ['username', 'fav_type', 'id']\n",
      "üìå Identification r√©ussie : Utilisateur = 'username', Anime = 'id'\n",
      "\n",
      "üìä Statistiques de la Matrice :\n",
      "   - Utilisateurs uniques : 246095\n",
      "   - Animes uniques      : 51585\n",
      "   - Sparsity            : 99.9671%\n"
     ]
    }
   ],
   "source": [
    "# --- CELLULE 4 : Analyse robuste et d√©tection ---\n",
    "\n",
    "# 1. On affiche les colonnes pour ne plus avancer √† l'aveugle\n",
    "cols = df_favs.columns.tolist()\n",
    "print(f\"üîç Colonnes pr√©sentes dans le fichier : {cols}\")\n",
    "\n",
    "# 2. D√©tection intelligente\n",
    "try:\n",
    "    # On cherche l'utilisateur (user, user_id, uid...)\n",
    "    col_user = [c for c in cols if 'user' in c or 'uid' in c][0]\n",
    "    \n",
    "    # On cherche l'anime : ce qui contient 'anime' OU ce qui contient 'id' \n",
    "    # mais qui n'est PAS la colonne utilisateur\n",
    "    potential_anime_cols = [c for c in cols if ('anime' in c or 'id' in c) and c != col_user]\n",
    "    \n",
    "    if not potential_anime_cols:\n",
    "        # Si on ne trouve rien, on prend la deuxi√®me colonne par d√©faut\n",
    "        col_anime = cols[1]\n",
    "    else:\n",
    "        col_anime = potential_anime_cols[0]\n",
    "\n",
    "    print(f\"üìå Identification r√©ussie : Utilisateur = '{col_user}', Anime = '{col_anime}'\")\n",
    "\n",
    "except IndexError:\n",
    "    print(\"‚ùå √âchec de la d√©tection automatique.\")\n",
    "    # Valeurs de secours (on prend les deux premi√®res colonnes)\n",
    "    col_user, col_anime = cols[0], cols[1]\n",
    "    print(f\"‚ö†Ô∏è Utilisation par d√©faut des colonnes : '{col_user}' et '{col_anime}'\")\n",
    "\n",
    "# 3. Calcul des statistiques\n",
    "n_users = df_favs[col_user].nunique()\n",
    "n_animes = df_favs[col_anime].nunique()\n",
    "sparsity = 1.0 - (len(df_favs) / (n_users * n_animes))\n",
    "\n",
    "print(f\"\\nüìä Statistiques de la Matrice :\")\n",
    "print(f\"   - Utilisateurs uniques : {n_users}\")\n",
    "print(f\"   - Animes uniques      : {n_animes}\")\n",
    "print(f\"   - Sparsity            : {sparsity:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98dd89",
   "metadata": {},
   "source": [
    "5. Pr√©traitement et Pivot Table\n",
    "On transforme la liste en matrice Animes x Utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67fb411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matrice pond√©r√©e cr√©√©e : (3064, 209291)\n"
     ]
    }
   ],
   "source": [
    "# --- CELLULE 5 : Filtrage et Matrice Pond√©r√©e (TF-IDF) ---\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 1. On garde ton filtrage de base\n",
    "min_user_favs = 5\n",
    "min_anime_favs = 150\n",
    "user_counts = df_favs['username'].value_counts()\n",
    "df_filtered = df_favs[df_favs['username'].isin(user_counts[user_counts >= MIN_USER].index)].copy()\n",
    "anime_counts = df_filtered['id'].value_counts()\n",
    "df_filtered = df_filtered[df_filtered['id'].isin(anime_counts[anime_counts >= MIN_ANIME].index)].copy()\n",
    "# 2. Encodage\n",
    "df_filtered['user_cat'] = df_filtered[col_user].astype('category')\n",
    "df_filtered['anime_cat'] = df_filtered[col_anime].astype('category')\n",
    "\n",
    "# 3. Cr√©ation de la matrice binaire\n",
    "user_anime_sparse = csr_matrix(\n",
    "    (np.ones(len(df_filtered)), (df_filtered['anime_cat'].cat.codes, df_filtered['user_cat'].cat.codes))\n",
    ")\n",
    "\n",
    "# 4. POND√âRATION TF-IDF (Nouveau : crucial pour la pertinence)\n",
    "# Cela r√©duit l'importance des utilisateurs \"bourrins\" et booste les \"s√©lectifs\"\n",
    "tfidf = TfidfTransformer()\n",
    "user_anime_weighted = tfidf.fit_transform(user_anime_sparse)\n",
    "\n",
    "mapped_anime_ids = df_filtered['anime_cat'].cat.categories\n",
    "print(f\"‚úÖ Matrice pond√©r√©e cr√©√©e : {user_anime_weighted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309053b",
   "metadata": {},
   "source": [
    "Optimisation des parametre par Algo d'opti \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2516726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Recherche du nombre optimal de facteurs latents (SVD)...\n",
      "üß© Composantes :  50 | Information conserv√©e : 4.82%\n",
      "üß© Composantes : 100 | Information conserv√©e : 7.69%\n",
      "üß© Composantes : 150 | Information conserv√©e : 10.26%\n",
      "üß© Composantes : 200 | Information conserv√©e : 12.67%\n",
      "üß© Composantes : 250 | Information conserv√©e : 14.99%\n",
      "üß© Composantes : 300 | Information conserv√©e : 17.22%\n",
      "üß© Composantes : 350 | Information conserv√©e : 19.37%\n",
      "üß© Composantes : 400 | Information conserv√©e : 21.46%\n",
      "üß© Composantes : 450 | Information conserv√©e : 23.50%\n",
      "üß© Composantes : 500 | Information conserv√©e : 25.50%\n",
      "\n",
      "üèÜ L'optimisation sugg√®re d'utiliser n_components = 500\n",
      "\n",
      "--- üìù MISE √Ä JOUR CONFIG ---\n",
      "svd_n_components: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "# --- PHASE D'OPTIMISATION (SVD TUNING) ---\n",
    "print(\"üìä Recherche du nombre optimal de facteurs latents (SVD)...\")\n",
    "\n",
    "# On teste diff√©rentes valeurs pour trouver le meilleur compromis\n",
    "n_components_list = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500,600, 650, 700, 750, 800, 850, 900, 950, 1000,]\n",
    "best_n = 100\n",
    "target_variance = 0.25 # On cherche √† capturer au moins 25% de la variance (typique en SVD creuse)\n",
    "\n",
    "for n in n_components_list:\n",
    "    svd_test = TruncatedSVD(n_components=n, random_state=42)\n",
    "    svd_test.fit(user_anime_weighted)\n",
    "    explained_variance = svd_test.explained_variance_ratio_.sum()\n",
    "    print(f\"üß© Composantes : {n:3} | Information conserv√©e : {explained_variance:.2%}\")\n",
    "    \n",
    "    if explained_variance >= target_variance:\n",
    "        best_n = n\n",
    "        break\n",
    "\n",
    "print(f\"\\nüèÜ L'optimisation sugg√®re d'utiliser n_components = {best_n}\")\n",
    "\n",
    "# --- üìù VALEURS √Ä COPIER DANS TA CONFIG ---\n",
    "print(\"\\n--- üìù MISE √Ä JOUR CONFIG ---\")\n",
    "print(f\"svd_n_components: {best_n}\")\n",
    "\n",
    "# On met √† jour la variable pour la suite du notebook\n",
    "N_COMPONENTS = best_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5afa7",
   "metadata": {},
   "source": [
    "6. Entra√Ænement du Mod√®le SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Mod√®le entra√Æn√© (1000 composantes).\n",
      "üìà Variance expliqu√©e : 7.69% (Cible > 40%)\n"
     ]
    }
   ],
   "source": [
    "# --- CELLULE 6 : SVD Haute R√©solution ---\n",
    "n_components = 0\n",
    "svd_final = TruncatedSVD(n_components=N_COMPONENTS, random_state=42)\n",
    "latent_matrix = svd_final.fit_transform(user_anime_weighted)\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(f\"üß† Mod√®le entra√Æn√© ({n_components} composantes).\")\n",
    "print(f\"üìà Variance expliqu√©e : {explained_variance:.2%} (Cible > 40%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1487e",
   "metadata": {},
   "source": [
    "7. Calcul de la Similarit√© Cosinus\n",
    "On calcule la ressemblance entre les animes dans l'espace r√©duit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc6f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matrice de similarit√© pr√™te.\n",
      "‚úÖ Matrice de similarit√© collaborative g√©n√©r√©e : (3064, 3064)\n",
      "üì¶ Taille en m√©moire : 37.64 MB\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la similarit√© cosinus dans l'espace r√©duit (Latent Space)\n",
    "# On convertit en float32 pour √©conomiser 50% de la RAM\n",
    "item_similarity = cosine_similarity(latent_matrix).astype(np.float32)\n",
    "\n",
    "df_similarity = pd.DataFrame(\n",
    "    item_similarity, \n",
    "    index=mapped_anime_ids, \n",
    "    columns=mapped_anime_ids\n",
    ")\n",
    "del item_similarity \n",
    "\n",
    "print(\"‚úÖ Matrice de similarit√© pr√™te.\")\n",
    "print(f\"‚úÖ Matrice de similarit√© collaborative g√©n√©r√©e : {df_similarity.shape}\")\n",
    "print(f\"üì¶ Taille en m√©moire : {df_similarity.memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62b168",
   "metadata": {},
   "source": [
    "8. Sauvegarde des Artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e6490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Succ√®s : La matrice SVD a √©t√© export√©e vers ../data/processed/svd_similarity_matrix.pkl\n",
      "‚úÖ Artefacts sauvegard√©s dans : ../runs/svd_collab_20260113_022236/artifacts/\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"../runs/svd_collab_{run_id}/artifacts/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# On sauvegarde la matrice de similarit√© pour l'utiliser dans le mod√®le hybride\n",
    "SVD_EXPORT_PATH = \"../data/processed/svd_similarity_matrix.pkl\"\n",
    "\n",
    "# Utilisation de pickle pour conserver la structure DataFrame et les types num√©riques\n",
    "df_similarity.to_pickle(SVD_EXPORT_PATH)\n",
    "\n",
    "print(f\"‚úÖ Succ√®s : La matrice SVD a √©t√© export√©e vers {SVD_EXPORT_PATH}\")\n",
    "\n",
    "joblib.dump(svd, f\"{save_dir}svd_model.joblib\")\n",
    "joblib.dump(df_similarity, f\"{save_dir}similarity_matrix.joblib\")\n",
    "print(f\"‚úÖ Artefacts sauvegard√©s dans : {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a2d98",
   "metadata": {},
   "source": [
    "9. Test du Mod√®le (Inf√©rence Collaborative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f3329a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations(anime_title, n_recs=10):\n",
    "    df_master = pd.read_csv(\"../data/processed/anime_master_clean.csv\")\n",
    "    id_col = 'mal_id' # Ton champ pivot\n",
    "    \n",
    "    matches = df_master[df_master['title'].str.contains(anime_title, case=False, na=False)]\n",
    "    if matches.empty: return \"Anim√© non trouv√©.\"\n",
    "    \n",
    "    target_data = matches.sort_values(by='members', ascending=False).iloc[0]\n",
    "    target_id = target_data[id_col]\n",
    "    \n",
    "    # 1. Obtenir les scores SVD bruts\n",
    "    if target_id not in df_similarity.index:\n",
    "        return f\"‚ö†Ô∏è Pas assez de donn√©es pour {target_data['title']}.\"\n",
    "    \n",
    "    similar_scores = df_similarity.loc[target_id]\n",
    "    \n",
    "    # 2. R√âPARATION : Pond√©ration par la popularit√© (Log-Scaling)\n",
    "    # On r√©cup√®re les candidats\n",
    "    candidate_ids = similar_scores.index\n",
    "    recs = df_master[df_master[id_col].isin(candidate_ids)].copy()\n",
    "    \n",
    "    # On r√©cup√®re le score SVD\n",
    "    recs['svd_pure'] = recs[id_col].map(similar_scores)\n",
    "    \n",
    "    # --- LA FORMULE DE R√âPARATION ---\n",
    "    # On multiplie le score SVD par le log de la popularit√© pour favoriser les titres solides\n",
    "    # tout en laissant une petite chance aux niches coh√©rentes.\n",
    "    recs['final_score'] = recs['svd_pure'] * np.log10(recs['members'])\n",
    "    \n",
    "    # 3. Nettoyage final (on enl√®ve la cible elle-m√™me)\n",
    "    result = recs[recs[id_col] != target_id].sort_values(by='final_score', ascending=False)\n",
    "    \n",
    "    print(f\"‚ú® R√©sultats corrig√©s pour : {target_data['title']}\")\n",
    "    return result.head(n_recs)[['title', 'genres_list', 'score', 'members', 'final_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43d52819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TEST DE R√âCOMPENSE POUR : Jujutsu Kaisen\n",
      "üìä Bas√© sur 4178747 interactions utilisateurs + Ton Master Clean\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres_list</th>\n",
       "      <th>score</th>\n",
       "      <th>members</th>\n",
       "      <th>svd_pure</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>Kimetsu no Yaiba</td>\n",
       "      <td>['Action', 'Award Winning', 'Supernatural']</td>\n",
       "      <td>8.42</td>\n",
       "      <td>3323322</td>\n",
       "      <td>0.730334</td>\n",
       "      <td>4.762924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>Jujutsu Kaisen 0 Movie</td>\n",
       "      <td>['Action', 'Supernatural']</td>\n",
       "      <td>8.39</td>\n",
       "      <td>1159463</td>\n",
       "      <td>0.753337</td>\n",
       "      <td>4.568431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>Jujutsu Kaisen 2nd Season</td>\n",
       "      <td>['Action', 'Supernatural']</td>\n",
       "      <td>8.73</td>\n",
       "      <td>1255502</td>\n",
       "      <td>0.690652</td>\n",
       "      <td>4.212161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22002</th>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "      <td>['Action', 'Award Winning', 'Drama', 'Suspense']</td>\n",
       "      <td>8.56</td>\n",
       "      <td>4230312</td>\n",
       "      <td>0.554913</td>\n",
       "      <td>3.677063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>Chainsaw Man</td>\n",
       "      <td>['Action', 'Fantasy']</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1813584</td>\n",
       "      <td>0.587469</td>\n",
       "      <td>3.676694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24943</th>\n",
       "      <td>Tokyo Revengers</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1365553</td>\n",
       "      <td>0.576749</td>\n",
       "      <td>3.538536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12301</th>\n",
       "      <td>Kimetsu no Yaiba: Yuukaku-hen</td>\n",
       "      <td>['Action', 'Supernatural']</td>\n",
       "      <td>8.71</td>\n",
       "      <td>1653797</td>\n",
       "      <td>0.552527</td>\n",
       "      <td>3.435880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>Blue Lock</td>\n",
       "      <td>['Sports']</td>\n",
       "      <td>8.16</td>\n",
       "      <td>842158</td>\n",
       "      <td>0.569786</td>\n",
       "      <td>3.376205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>Jigokuraku</td>\n",
       "      <td>['Action', 'Adventure', 'Supernatural']</td>\n",
       "      <td>8.09</td>\n",
       "      <td>858418</td>\n",
       "      <td>0.551359</td>\n",
       "      <td>3.271596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23206</th>\n",
       "      <td>Spy x Family</td>\n",
       "      <td>['Action', 'Award Winning', 'Comedy']</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1794468</td>\n",
       "      <td>0.472730</td>\n",
       "      <td>2.956425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "12291               Kimetsu no Yaiba   \n",
       "10961         Jujutsu Kaisen 0 Movie   \n",
       "10962      Jujutsu Kaisen 2nd Season   \n",
       "22002             Shingeki no Kyojin   \n",
       "3334                    Chainsaw Man   \n",
       "24943                Tokyo Revengers   \n",
       "12301  Kimetsu no Yaiba: Yuukaku-hen   \n",
       "2554                       Blue Lock   \n",
       "10663                     Jigokuraku   \n",
       "23206                   Spy x Family   \n",
       "\n",
       "                                            genres_list  score  members  \\\n",
       "12291       ['Action', 'Award Winning', 'Supernatural']   8.42  3323322   \n",
       "10961                        ['Action', 'Supernatural']   8.39  1159463   \n",
       "10962                        ['Action', 'Supernatural']   8.73  1255502   \n",
       "22002  ['Action', 'Award Winning', 'Drama', 'Suspense']   8.56  4230312   \n",
       "3334                              ['Action', 'Fantasy']   8.44  1813584   \n",
       "24943                               ['Action', 'Drama']   7.84  1365553   \n",
       "12301                        ['Action', 'Supernatural']   8.71  1653797   \n",
       "2554                                         ['Sports']   8.16   842158   \n",
       "10663           ['Action', 'Adventure', 'Supernatural']   8.09   858418   \n",
       "23206             ['Action', 'Award Winning', 'Comedy']   8.44  1794468   \n",
       "\n",
       "       svd_pure  final_score  \n",
       "12291  0.730334     4.762924  \n",
       "10961  0.753337     4.568431  \n",
       "10962  0.690652     4.212161  \n",
       "22002  0.554913     3.677063  \n",
       "3334   0.587469     3.676694  \n",
       "24943  0.576749     3.538536  \n",
       "12301  0.552527     3.435880  \n",
       "2554   0.569786     3.376205  \n",
       "10663  0.551359     3.271596  \n",
       "23206  0.472730     2.956425  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def test_repaired_model(anime_name, n_recs=10):\n",
    "    # 1. Chargement de ta source de v√©rit√©\n",
    "    df_master = pd.read_csv(\"../data/processed/anime_master_clean.csv\")\n",
    "    \n",
    "    # 2. On trouve l'ID mal_id de ton anim√©\n",
    "    matches = df_master[df_master['title'].str.contains(anime_name, case=False, na=False)]\n",
    "    if matches.empty: return print(f\"‚ùå '{anime_name}' non trouv√©.\")\n",
    "    \n",
    "    target = matches.sort_values(by='members', ascending=False).iloc[0]\n",
    "    t_id = target['mal_id']\n",
    "    \n",
    "    if t_id not in df_similarity.index:\n",
    "        return print(f\"‚ö†Ô∏è Pas assez de donn√©es pour '{target['title']}'\")\n",
    "\n",
    "    # 3. Calcul du score REPAR√â\n",
    "    # On r√©cup√®re tous les scores de similarit√© pour cet anim√©\n",
    "    sim_scores = df_similarity.loc[t_id]\n",
    "    \n",
    "    # On cr√©e un DataFrame de travail\n",
    "    df_recs = df_master[df_master['mal_id'].isin(sim_scores.index)].copy()\n",
    "    df_recs['svd_pure'] = df_recs['mal_id'].map(sim_scores)\n",
    "    \n",
    "    # --- LA FORMULE DE R√âPARATION ---\n",
    "    # On multiplie la similarit√© par le log de la popularit√© (members)\n",
    "    # Cela donne un coup de pouce aux anim√©s que beaucoup de gens ont valid√©\n",
    "    df_recs['final_score'] = df_recs['svd_pure'] * np.log10(df_recs['members'])\n",
    "    \n",
    "    # 4. On pr√©pare l'affichage\n",
    "    # On enl√®ve l'anim√© lui-m√™me\n",
    "    df_recs = df_recs[df_recs['mal_id'] != t_id]\n",
    "    \n",
    "    # Tri par le nouveau score\n",
    "    result = df_recs.sort_values(by='final_score', ascending=False).head(n_recs)\n",
    "    \n",
    "    print(f\"üöÄ TEST DE R√âCOMPENSE POUR : {target['title']}\")\n",
    "    print(f\"üìä Bas√© sur {len(df_favs)} interactions utilisateurs + Ton Master Clean\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    return result[['title', 'genres_list', 'score', 'members', 'svd_pure', 'final_score']]\n",
    "\n",
    "# --- LANCEMENT DU TEST ---\n",
    "test_repaired_model(\"jujutsu kaisen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
